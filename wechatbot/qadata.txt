智算网络V100是支持外网访问吗？	支持
智算集群如何使用的公开数据集？	可以参考示例（可以点击启动文件右侧的“查看示例”）
智算网络可以选择自定义镜像吗？	目前智算网络只能使用公网镜像
如果使用智算网络还需要下载数据集吗？	不需要，在训练任务直接选择数据集就可以，数据集和代码会放入容器内指定路径，训练脚本需要按照这个来
云脑训练任务结果保存多长时间？	目前没有限定时间，但如果磁盘满了，或者总任务数超了之后，可能会清理，清理之前平台会发公告。
训练任务如果需要安装别的第三方库应该怎么操作？	需要在调试环境安装好第三方库，提交成新的镜像，然后训练的时候，选择此镜像即可。
NPU调试环境的硬盘空间有多大？	目前是100G。
训练任务已结束，计算资源为CPU/GPU，状态为succeeded，但是为什么在模型页面还显示没创建过训练任务呢？	导入模型功能暂时只支持从NPU训练任务导入，这里的提示语需要改一下的，建议提Issue跟踪。
若从CPU/GPU切换到NPU的训练任务，那对原来的pytorch代码改动大么？	视情况而定，NPU上目前支持的框架是MindSpore和TensorFlow。
请问调试任务能正常运行，但训练任务总是failed是什么原因呢？	可以检查下是否填写了正确的启动文件，需要填写在代码仓的相对路径。另外，目前GPU训练的日志只支持在代码中print输出日志，系统报错不会打印出来。训练卡是A100，建议使用推荐镜像是cuda11以上的镜像进行调试后，再跑训练。
上传训练任务对应的数据集有没有大小限制？	有限制，单次最多上传10个文件，每个不超过200G。
怎么在训练前安装好自己需要的包呢？	镜像大小限时20GB限制，如果平台没有符合的包，可以通过python脚本安装。
平台是否有上多数据集的示例？	请参考教程【https://git.openi.org.cn/OpenIOSSG/MNIST_Example】
在创建调试任务时，如果数据集分别在不同的文件夹，【新建任务】中的数据集部分如何处理呢？	可以将不同的文件夹打包到一个Zip包，或者选择多个Zip包，根据自己的需求，控制脚本。
数据集过大被拆分成多个文件上传时，支持选中数据集内多个文件吗，或者说直接选中整个数据集？	训练任务支持多个数据集文件的已加入需求列表，近期会解决，可以提Issue跟踪。
现在公开发布的镜像都哪些可适用于A100？标签或者镜像描述中没有写适用A100的某些镜像是否可用？	A100需要cuda11以上的版本，其他公开镜像如果满足要求，也可以用。基础镜像是【dockerhub.pcl.ac.cn:5000/user-images/openi:ssbai_torch1.9】，包含pytorch1.9，python3.8，cuda11.1
有哪些适用于PyTorch进行训练的镜像？	要使用含有PyTorch的镜像训练的话，建议选择平台推荐的这个镜像dockerhub.pcl.ac.cn:5000/user-images/openi:cuda111_python37_pytorch191，PyTorch1.9也是兼容1.8的。
保存镜像时，是将数据集、代码、以及生成的Model都打包在里头了吗?	不会，只是打包安装的一些软件，当使用镜像开训练任务时，实际上用的还是仓库内的代码。调试完代码记得push一下，这样训练的时候用的也是最新的代码了。
数据集已经有了，为什么在“新建调试任务”中找不到呢？	请确认数据集是否为ZIP格式，只有上传ZIP格式的数据集才能发起云脑任务。
平台上有基于ubuntu 18的镜像吗？是否支持创建基于自己操作系统的镜像？	暂时没有此镜像，支持使用自己的公开镜像仓库，可以创建一个试试。
提交的镜像不能超过20G的问题怎么处理？	镜像超过20G时，可以通过直接输入公开镜像库的地址规避解决，在创建云脑任务选择镜像的时候，可以直接输入公开镜像库的地址。
NPU选择MindSpore1.6的环境，Git命令为什么执行不了？	可能是这个镜像里没有安装Git，可以尝试1.5的环境。
有没有mindspore的省显存的方法？	1. 重计算方法，请参考教程【https://www.mindspore.cn/docs/zh-CN/r1.7/design/recompute.html】 2. 梯度累积方法，请参考教程【https://www.mindspore.cn/tutorials/experts/zh-CN/r1.7/others/gradient_accumulation.html】
MindSpore并行处理有没有相关教程指导？	有的，C76环境教程请参考页面链接【https://git.openi.org.cn/PCL-Platform.Intelligence/Hybrid-Parallel-Solutions-MindSpore】； 支持GPU/NPU的C78环境教程请参考页面链接【https://git.openi.org.cn/PCL-Platform.Intelligence/mPanGu-Alpha-53】。 配置环境和数据集构建教程请参考Mindspore官网教程【https://www.mindspore.cn/tutorials/experts/zh-CN/r1.7/parallel/train_ascend.html】。 关于MindSpore的相关问题，可以去昇腾论坛【https://bbs.huaweicloud.com/forum/forum-726-1.html】 查询和发帖求助。
云上能否使用MindSpore1.6以上的版本？	目前调试和训练环境已支持到1.6版本，更高版本要自制镜像，欢迎到小白训练营提Issue跟踪。
CPU转Ascend要改什么内容呢？	MindSpore对算子的支持，NPU>GPU>CPU，硬件不一样API可能有变化，可以去MindSpore官网看下版本API的信息, 或者参考下开源项目里相关API的使用，建议提一下Issue。
跑分布式都是用MindSpore的model.train形式的api跑吗？有没有写成类似torch里面， for训练，每个epoch下，读取数据，输入网络，更新权重的形式的呢？	MindSpore有自动并行，可以参考教程【https://mindspore.cn/docs/zh-CN/r1.7/design/distributed_training_design.html】
创建项目需要docker吗？	不需要，平台有相应的镜像还有数据集，收藏就可以直接用，代码可以直接上传，也可以从外部直接迁移项目。
code目录上传文件有大小限制么？	是的，有大小限制，大文件不适合用git去做管理，后续平台支持多数据集选择时，就能解决这个问题了，欢迎提Issue跟踪。
项目代码显示不全，如何修改或删除？	可以自己手动执行Git拉代码，即先把代码git clone到本地，修改或删除代码文件，然后再Push。
自动挂载的/userhome中的文件会不会被打包进镜像？	不会。
/userhome这个目录是大家公用的？随便读写？	是的，这是个公共空间，所有人可见。
请问训练任务能否读取到/userhome？	可以，但是不建议这么做，/userhome目录是所有人都能访问的，有读写权限，那里的数据不保证安全。
训练结束后，为什么下载的日志文件和页面显示的文件大小不一致？好像一直是第一次下载的内容	log.txt记录的是训练脚本中的输出，如果没有输出那就没有变化。另，下载同名文件，浏览器会使用缓存，请及时清理浏览器缓存。
